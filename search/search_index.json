{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About Me","text":""},{"location":"#build-ai-solutions-that-work-for-your-business","title":"Build AI solutions that work for your business","text":""},{"location":"#i-help-you-move-from-ai-hype-to-real-results","title":"I help you move from AI hype to real results","text":"<ul> <li>Struggling to figure out where AI actually fits in your business?</li> <li>Drowning in vendor pitches but need someone who speaks both tech and strategy?</li> <li>Want to build your first AI system?</li> <li>Need a freelancer who can code the solution and train your team?</li> </ul> <p>Book Free Intro Call </p>"},{"location":"#about-me","title":"About me","text":"<p>Hi! I\u2019m Katharina, a freelance AI engineer based in Berlin. I help companies cut through AI hype and build solutions that actually work \u2014 RAG systems, LLM applications, document processing, and intelligent automation.</p> <p>My approach: Understand the problem deeply, work with the data you have (not the data you wish you had), and ship pragmatic solutions your team will actually use.</p> <p>What makes me different:</p> <p>I\u2019ve been exploring generative AI since 2019 \u2014 back when we were using GANs, 3 years before ChatGPT made it mainstream. I\u2019ve spent nearly 10 years across healthcare, startups, and retail learning one critical lesson: the best AI projects start with good data and people willing to adapt the technology, not fancy models.</p> <p>I\u2019m not the person who built AI at scale at Google. I\u2019m the person who helps mid-sized and small companies actually get started.</p> <p>My background:     \u2022   Built production ML pipelines for certified medical AI devices (FHIR, GDPR-compliant)     \u2022   Designed and taught 20-hour data science courses to 100+ managers and engineers     \u2022   Delivered AI strategy workshops and proof-of-concepts across multiple industries     \u2022   Currently focused on RAG systems, chatbots, and document intelligence using OpenAI, Claude, and open-source models</p> <p>My tech stack: Python, PostgreSQL, LangChain, OpenAI/Claude APIs, FastAPI, Docker, Pinecone/Weaviate, MLFlow</p>"},{"location":"#why-work-with-me","title":"Why work with me?","text":"<p>Here's why I'm the right fit and what you'll gain from working together:</p> <ul> <li> <p> Fast Implementation &amp; Strategy</p> <p>I can evaluate your use case, recommend an approach, and build it. Most consultants do one or the other. I do both. Whether you need a workshop to figure out where AI fits or hands-on engineering to ship a prototype, I\u2019ve got you covered.</p> </li> <li> <p> Pragmatic, Not Perfectionist</p> <p>I'm a practitioner, not just a theorist. I recently transitioned to freelancing after building real AI systems, so I understand both the technical challenges and the business impact. Whether it's RAG implementation, LLM integration, or data pipeline optimization, I bring battle-tested solutions to the table.</p> </li> <li> <p> Clear Communication</p> <p>I break down complex AI concepts into clear, actionable insights. You'll always understand the 'why' behind technical decisions. I provide regular progress updates, thorough documentation, and collaborate closely with your team to ensure we're aligned every step of the way.</p> </li> <li> <p> Continuous Learning &amp; Innovation</p> <p>I\u2019ve trained 100+ people in data science and ML. I don\u2019t just hand you code\u2014I explain the why behind decisions, document everything (using MkDocs), and make sure your team can maintain what we build. I see the big picture while debugging the details. Early AI adopter who\u2019s stayed current through every wave (GANs \u2192 Transformers \u2192 LLMs). AI moves fast, and so do I.</p> </li> </ul> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"},{"location":"#frequently-asked-questions","title":"Frequently asked questions","text":"How quickly can you start working on my project? <p>I'm usually ready to kick off new projects within 1-2 weeks after we finalize the contract. If you're working against a tight deadline, I'm happy to discuss accelerated timelines\u2014just give me a heads up during our first conversation about what you're working with.</p> Do you require a minimum project size or commitment? <p>I work with projects of all sizes, but I've found that around 20 hours is the sweet spot to really dig into your challenge, understand your data landscape, and deliver solutions that actually move the needle. If you're unsure about fit, we can always start with a smaller pilot to see if we click.</p> What industries have you worked in? <p>I've tackled projects in healthcare, retail, and insurance. While the fundamentals of data work transcend industries, I've built particular expertise in understanding customer behavior, streamlining operations, and building predictive models that drive real business outcomes.</p> How do you handle data security and confidentiality? <p>Data security isn't negotiable for me. I sign NDAs as standard practice, encrypt all data in transit, and adhere to industry security standards. I'm also comfortable integrating with your existing security setup and compliance requirements\u2014we can work however makes you most comfortable.</p> What's your pricing model? <p>I offer both project-based and ongoing retainer options. Project pricing reflects the scope, complexity, and value you'll get\u2014not just hours on the clock. For continuous support, I design retainers that fit your actual needs. Let's talk about your situation and find an approach that makes financial sense.</p> How do you keep me in the loop? <p>I believe in transparency. You'll get weekly updates on progress, regular sync meetings, and thorough documentation of everything we discover and build. For longer engagements, I set up dashboards and reports so you can see results as they happen, not just at the end</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"blog/posts/cursor-code-workspace-files/","title":"Opening VS Code Workspace Files with Cursor on macOS","text":"<p>I recently switched to Cursor, a new AI-enhanced code editor that's been getting a lot of attention lately. While it's been a great experience so far, there was one small hiccup on macOS with <code>.code-workspace</code> files. Here's how I solved it.</p>"},{"location":"blog/posts/cursor-code-workspace-files/#why-cursor","title":"Why Cursor?","text":"<p>If you're a developer, you might have noticed Cursor IDE popping up everywhere. It's a fork of VS Code but with added AI capabilities like autocomplete, inline edits, and a composer. After five years with VS Code, I decided to give Cursor a try. The transition was seamless since Cursor is built on top of VS Code, so all my settings, themes, and extensions worked right out of the box.</p>"},{"location":"blog/posts/cursor-code-workspace-files/#the-macos-workspace-issue","title":"The macOS Workspace Issue","text":"<p>One issue I ran into was with opening <code>.code-workspace</code> files on macOS. By default, Cursor couldn't open these files directly, which was pretty annoying. Fortunately, there's a straightforward fix.</p>"},{"location":"blog/posts/cursor-code-workspace-files/#how-to-make-cursor-the-default-for-workspace-files","title":"How to Make Cursor the Default for Workspace Files","text":"<p>Here's how to make Cursor the default application for <code>.code-workspace</code> files:</p> <ol> <li>Locate a <code>.code-workspace</code> file in Finder.</li> <li>Right-click on the file and select \u201cGet Info\u201d from the context menu.</li> <li>In the \u201cGet Info\u201d window, look for the \u201cOpen with:\u201d section.</li> <li>Click on the selection field and choose \"Other\".</li> <li>In the Finder selection window, change the setting \"Enable\" to \"All Applications\" instead of the default \"Recommended Applications\"(1)</li> <li>You can now select Cursor from the list.</li> <li>After making the selection, click \"Change All...\" to make Cursor the default for all your <code>.code-workspace</code> files.</li> </ol> <ol> <li>This is where you need to change the setting to \"All Applications\".     </li> </ol>"},{"location":"blog/posts/uv-python-package-manager/","title":"Getting Started with UV: The Ultra-Fast Python Package Manager","text":"<p>If you're tired of slow package installations and complex dependency management in Python, uv might be exactly what you need. Written in Rust, uv is a blazing-fast package manager that aims to replace pip, pip-tools, pipx, poetry, and more. Let's dive into why it's awesome and how to get started.</p>"},{"location":"blog/posts/uv-python-package-manager/#why-uv","title":"Why UV?","text":"<p>After years of wrestling with different Python package managers, uv caught my attention for a few key reasons:</p> <ul> <li>It's 10-100x faster than pip</li> <li>Single tool to replace multiple package managers</li> <li>Universal lockfile support for consistent environments</li> <li>Built-in Python version management</li> </ul>"},{"location":"blog/posts/uv-python-package-manager/#installation","title":"Installation","text":"<p>Getting started with uv is straightforward. Here are the installation methods I recommend for each platform:</p>"},{"location":"blog/posts/uv-python-package-manager/#macos-using-homebrew","title":"macOS (using Homebrew)","text":"<pre><code>brew install uv\n</code></pre>"},{"location":"blog/posts/uv-python-package-manager/#linuxmacos-using-curl","title":"Linux/macOS (using curl)","text":"<pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre>"},{"location":"blog/posts/uv-python-package-manager/#windows-using-powershell","title":"Windows (using PowerShell)","text":"<pre><code>powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre>"},{"location":"blog/posts/uv-python-package-manager/#managing-python-versions","title":"Managing Python Versions","text":"<p>While you probably already have Python installed on your system, uv can manage Python versions for you. Here's how:</p> <pre><code># List available Python versions\nuv python list\n\n# Install a specific version\nuv python install 3.12\n\n# Use a specific version for your project\nuv python pin 3.12\n</code></pre>"},{"location":"blog/posts/uv-python-package-manager/#creating-a-new-project","title":"Creating a New Project","text":"<p>Let's create a new project and see uv in action:</p> <pre><code># Create a new project directory\nmkdir my-awesome-project\ncd my-awesome-project\n\n# Initialize a new project\nuv init\n\n# Create and activate a virtual environment\nuv venv\nsource .venv/bin/activate  # On Windows: .venv\\Scripts\\activate\n</code></pre> <p>This creates a basic project structure with a <code>pyproject.toml</code> file, which is similar to package.json for Node.js developers.</p>"},{"location":"blog/posts/uv-python-package-manager/#managing-dependencies","title":"Managing Dependencies","text":"<p>Here's where uv really shines. Let's add some common packages:</p> <pre><code># Add a single package\nuv add requests\n\n# Add multiple packages with specific versions\nuv add 'fastapi&gt;=0.100.0' pytest\n\n# Add development dependencies\nuv add --dev black ruff\n</code></pre>"},{"location":"blog/posts/uv-python-package-manager/#working-with-requirementstxt","title":"Working with requirements.txt","text":"<p>If you're working with an existing project that uses requirements.txt, uv has got you covered:</p> <pre><code># Install from requirements.txt\nuv pip install -r requirements.txt\n\n# Generate a requirements.txt from your project\nuv pip freeze &gt; requirements.txt\n</code></pre>"},{"location":"blog/posts/uv-python-package-manager/#understanding-the-lock-file","title":"Understanding the Lock File","text":"<p>One of uv's best features is its lockfile system. When you run <code>uv add</code> or <code>uv sync</code>, it creates/updates a <code>uv.lock</code> file that ensures consistent installations across all environments. This is similar to package-lock.json in Node.js or Cargo.lock in Rust.</p> <pre><code># Manually update the lockfile\nuv lock\n\n# Sync your environment with the lockfile\nuv sync\n</code></pre>"},{"location":"blog/posts/uv-python-package-manager/#daily-usage-tips","title":"Daily Usage Tips","text":"<p>Here are some common commands you'll use regularly:</p> <pre><code># Remove a package\nuv remove requests\n\n# Update a specific package\nuv lock --upgrade-package requests\n\n# Run a Python script in your environment\nuv run script.py\n\n# Install a tool globally (like pipx)\nuv tool install ruff\n</code></pre>"},{"location":"blog/posts/uv-python-package-manager/#why-i-switched-to-uv","title":"Why I Switched to UV","text":"<p>After using uv for several weeks, the speed difference is incredible. What used to take minutes with pip now takes seconds. The unified interface for managing both packages and Python versions has simplified my workflow significantly.</p> <p>Here's a quick comparison installing a complex package:</p> <pre><code># With pip\ntime pip install tensorflow  # ~2-3 minutes\n\n# With uv\ntime uv pip install tensorflow  # ~15-20 seconds\n</code></pre>"},{"location":"blog/posts/uv-python-package-manager/#next-steps","title":"Next Steps","text":"<p>To get the most out of uv, I recommend:</p> <ol> <li>Adding <code>.venv</code> to your <code>.gitignore</code></li> <li>Committing both <code>pyproject.toml</code> and <code>uv.lock</code> to version control</li> <li>Using <code>uv sync</code> instead of <code>pip install</code> to ensure consistent environments</li> </ol> <p>Uv is actively maintained by the team behind Ruff (another amazing Python tool), and it's quickly becoming the go-to package manager in the Python ecosystem. You can find more resources and documentation here.</p>"},{"location":"portfolio/","title":"Featured Projects","text":"<p>Welcome to my portfolio of data science and AI projects. Each project demonstrates my expertise in delivering impactful solutions to real-world business challenges.</p> <ul> <li> <p>AI Meal Planner</p> <p>AI-Powered Meal Planning Assistant with RAG and LLMs to suggest personalized meals and generate weekly plans from 2M+ recipes.</p> </li> </ul>"},{"location":"portfolio/projects/mealprep_portfolio/","title":"AI-Powered Meal Planning Assistant","text":"Portfolio Best Practices <p>This is a portfolio project demonstrating RAG implementation and full-stack AI development. Key highlights:</p> <ul> <li>End-to-end RAG pipeline with semantic search</li> <li>PostgreSQL + pgvector for production-grade vector storage</li> <li>Structured outputs using Pydantic models</li> <li>Docker-based deployment with service orchestration</li> <li>Clean separation of concerns (UI, business logic, data layer)</li> <li>Scalable architecture supporting 2M+ recipe embeddings</li> </ul> <p>Project Summary</p> <p>Project: MealPrep - AI Meal Planning Assistant Repository: GitHub Category: Personal AI Application  </p> <p>Key Features:</p> <ul> <li>Semantic search across 2.2M+ recipes using RAG</li> <li>Single meal suggestions based on available ingredients</li> <li>Multi-day meal plan generation with shopping lists</li> <li>Real-time meal regeneration with diversity enforcement</li> <li>PostgreSQL database with meal plan persistence</li> <li>Built from scratch in 1 week</li> </ul> <p>An intelligent meal planning application that combines Retrieval-Augmented Generation (RAG) with Large Language Models to deliver personalized meal suggestions and automated weekly meal plans based on available ingredients and dietary preferences.</p>"},{"location":"portfolio/projects/mealprep_portfolio/#challenge","title":"Challenge","text":"<p>Planning meals daily is time-consuming and often results in repetitive choices. Existing meal planning apps lack:</p> <ul> <li>Intelligent suggestions based on what you already have</li> <li>True variety - they suggest similar meals repeatedly</li> <li>Flexibility - rigid plans that don't adapt to rejections</li> <li>Semantic understanding - can't find similar recipes or adapt to preferences</li> </ul> <p>The goal was to build an AI-powered solution that understands context, ensures variety, and learns from user preferences while leveraging a massive recipe database.</p>"},{"location":"portfolio/projects/mealprep_portfolio/#our-approach","title":"Our Approach","text":"<p>Developed a full-stack RAG application with two distinct modes:</p> <p>Mode 1: Single Meal Suggestion</p> <ul> <li>Ingredient-based semantic search through 2M+ recipes</li> <li>RAG pipeline retrieves similar recipes as context</li> <li>LLM (OpenAI GPT-5-mini) generates personalized suggestions considering dietary preferences</li> <li>Accept/reject workflow with automatic diversity enforcement</li> </ul> <p>Mode 2: Multi-Day Meal Planning</p> <ul> <li>Automated generation of X day meal plans</li> <li>Individual meal acceptance/rejection with on-the-fly regeneration</li> <li>Shopping list aggregation from accepted meals</li> <li>Plan persistence with database storage</li> </ul> <p>Technical Implementation:</p> <ul> <li>Embedded 2.2M recipes using sentence-transformers (text-embedding-3-small)</li> <li>Vector similarity search with pgvector and PostgreSQL</li> <li>Structured outputs using Pydantic for reliable parsing</li> <li>Prompt engineering for diversity and creativity</li> </ul>"},{"location":"portfolio/projects/mealprep_portfolio/#results-impact","title":"Results &amp; Impact","text":"<ul> <li>Successfully processes 2.2M+ recipe embeddings</li> <li>Sub-second semantic search response times</li> <li>Reliable structured outputs using Pydantic validation</li> <li>Meal plan generation in under 30 seconds for 7-day plans</li> <li>Docker deployment with persistent storage</li> <li>Clean architecture enabling easy feature additions</li> </ul>"},{"location":"portfolio/projects/mealprep_portfolio/#solution-overview","title":"Solution Overview","text":""},{"location":"portfolio/projects/mealprep_portfolio/#architecture","title":"Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Streamlit  \u2502  UI Layer\n\u2502     UI      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Meal Service   \u2502  Business Logic\n\u2502   (RAG Flow)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Vector Store    \u2502\u2500\u2500\u2500\u2500\u25b6\u2502  PostgreSQL \u2502\n\u2502  (pgvector)     \u2502     \u2502  + pgvector \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Claude API    \u2502  LLM Generation\n\u2502   (Sonnet 4)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"portfolio/projects/mealprep_portfolio/#rag-pipeline","title":"RAG Pipeline","text":"<ol> <li> <p>Indexing Phase:</p> <ul> <li>Load 2.2M recipes from Kaggle dataset</li> <li>Generate embeddings using sentence-transformers</li> <li>Store in PostgreSQL with pgvector extension</li> </ul> </li> <li> <p>Retrieval Phase:</p> <ul> <li>User inputs ingredients</li> <li>Semantic search finds similar recipes (cosine similarity)</li> <li>Top-k results retrieved as context</li> </ul> </li> <li> <p>Generation Phase:</p> <ul> <li>Similar recipes passed to OpenAI as system context</li> <li>Prompt includes ingredients, dietary preferences, excluded meals</li> <li>Structured output ensures consistent parsing</li> </ul> </li> <li> <p>Diversity Enforcement:</p> <ul> <li>Recent meals tracked in database</li> <li>Rejected meals added to exclusion list</li> <li>Prompt explicitly instructs variety across cuisines and methods</li> </ul> </li> </ol>"},{"location":"portfolio/projects/mealprep_portfolio/#tech-stack","title":"Tech Stack","text":"<p>AI &amp; Machine Learning</p> <ul> <li>OpenAI GPT-5-mini for meal generation</li> <li>sentence-transformers (text-embedding-3-small) for embeddings</li> <li>pgvector for vector similarity search</li> <li>Custom RAG pipeline implementation</li> </ul> <p>Backend</p> <ul> <li>Python 3.12</li> <li>Streamlit for rapid UI development</li> <li>PostgreSQL with pgvector extension</li> <li>Pydantic for data validation</li> <li>psycopg2 for database connectivity</li> </ul> <p>Data Processing</p> <ul> <li>Pandas for recipe data manipulation (added diet classifications)</li> <li>2.2M recipe dataset from Kaggle</li> </ul> <p>Infrastructure</p> <ul> <li>Docker &amp; Docker Compose for service orchestration</li> <li>uv for fast Python package management</li> <li>python-dotenv for configuration management</li> </ul> <p>Development</p> <ul> <li>Git for version control</li> <li>Structured project layout with separation of concerns</li> </ul>"},{"location":"portfolio/projects/mealprep_portfolio/#additional-context","title":"Additional Context","text":"<ul> <li>Timeline: 1 week</li> <li>Team Size: Solo project</li> <li>Role: Full-stack AI Engineer</li> <li>Dataset: 2.2M+ recipes from Kaggle</li> <li>Learning Focus: Production RAG implementation, vector databases, structured outputs</li> </ul> <p>Future Enhancements:</p> <ul> <li>Shopping list integration with grocery apps</li> <li>MCP (Model Context Protocol) integration with growing RAG database (see below)</li> <li>Advanced text chunking for recipe processing</li> <li>PDF cookbook parsing</li> <li>Nutritional tracking</li> <li>Calendar integration for meal scheduling</li> </ul>"},{"location":"portfolio/projects/mealprep_portfolio/#learnings-insights","title":"Learnings &amp; Insights","text":"<p>Technical Challenges Solved:</p> <ol> <li>Scale: Efficiently embedding and searching 2M+ recipes</li> <li>Parsing Reliability: Structured outputs improved parsing</li> <li>Diversity: Prompt engineering crucial for non-repetitive suggestions</li> <li>State Management: Streamlit session state for complex workflows</li> </ol> <p>Key Takeaways:</p> <ul> <li>RAG quality depends heavily on retrieval strategy</li> <li>Prompt engineering is as important as model choice</li> <li>Structured outputs essential for production reliability</li> <li>Docker simplifies local development and deployment</li> </ul> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"},{"location":"portfolio/projects/project-1/","title":"AI Customer Care Bot for Dev X","text":"Portfolio Best Practices <p>This is a simplified example project. When creating your own portfolio:</p> <ul> <li>Include detailed technical challenges and how you solved them</li> <li>Add specific metrics and KPIs that demonstrate impact</li> <li>Show code snippets of interesting implementations</li> <li>Include architecture diagrams and system designs</li> <li>Document your decision-making process</li> <li>Highlight your specific contributions to the project</li> <li>Add visuals of the final product (if possible)</li> </ul> <p>Case Study Summary</p> <p>Client: Dev X Website: devx.com Industry: Software Development  </p> <p>Impact Metrics:</p> <ul> <li>90% reduction in customer service overhead (projected)</li> <li>100% accuracy on initial evaluation datasets</li> <li>&lt; 3 second response time for customer inquiries</li> <li>Successfully transitioned 12 CSRs to account management roles</li> <li>$240,000 annual cost savings in customer support operations</li> </ul> <p>Dev X aims to reduce its customer service overhead by 90% over the next three years through AI, enabling their staff to focus on more rewarding roles and build better relationships with clients.</p>"},{"location":"portfolio/projects/project-1/#challenge","title":"Challenge","text":"<p>Their strategy involved transitioning customer service representatives to more rewarding account manager roles to enhance client relationships. They needed an AI solution that could efficiently handle routine customer inquiries while integrating seamlessly with their existing workflows.</p>"},{"location":"portfolio/projects/project-1/#our-approach","title":"Our Approach","text":"<p>We developed an AI chatbot specifically for Dev X's internal use, designed to assist customer service representatives in quickly accessing information. The solution was seamlessly integrated within Slack, the platform already used by their team, allowing for minimal disruption to existing workflows.</p>"},{"location":"portfolio/projects/project-1/#results-impact","title":"Results &amp; Impact","text":"<ul> <li>Response time under 3 seconds</li> <li>100% accuracy on initial evaluation datasets</li> <li>Successful integration with existing Slack workflows</li> <li>Currently expanding knowledge base coverage</li> <li>Simple activation through Slack mentions</li> </ul>"},{"location":"portfolio/projects/project-1/#solution-overview","title":"Solution Overview","text":"<p>Baseline OpenAI end-to-end chat reference architecture</p>"},{"location":"portfolio/projects/project-1/#tech-stack","title":"Tech Stack","text":"<ul> <li>OpenAI</li> <li>Pinecone vector database</li> <li>Slack API integration</li> <li>Microsoft Azure cloud infrastructure</li> <li>Python backend services</li> <li>FastAPI for RESTful endpoints</li> <li>Docker containerization</li> <li>GitHub Actions for CI/CD pipeline</li> </ul>"},{"location":"portfolio/projects/project-1/#additional-context","title":"Additional Context","text":"<ul> <li>Timeline: 3 months</li> <li>Team Size: 2 people (AI Engineer and Data Engineer)</li> <li>Role: AI Engineer</li> <li>Close collaboration with customer service team</li> <li>Ongoing knowledge base expansion</li> <li>Future plans include implementing feedback mechanism</li> </ul> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"},{"location":"portfolio/projects/project-2/","title":"Enterprise Chatbot for the Company Y","text":"Portfolio Best Practices <p>This is a simplified example project. When creating your own portfolio:</p> <ul> <li>Include detailed technical challenges and how you solved them</li> <li>Add specific metrics and KPIs that demonstrate impact</li> <li>Show code snippets of interesting implementations</li> <li>Include architecture diagrams and system designs</li> <li>Document your decision-making process</li> <li>Highlight your specific contributions to the project</li> <li>Add visuals of the final product (if possible)</li> </ul> <p>Case Study Summary</p> <p>Client: Dev X Website: devx.com Industry: Software Development  </p> <p>Impact Metrics:</p> <ul> <li>90% reduction in customer service overhead (projected)</li> <li>100% accuracy on initial evaluation datasets</li> <li>&lt; 3 second response time for customer inquiries</li> <li>Successfully transitioned 12 CSRs to account management roles</li> <li>$240,000 annual cost savings in customer support operations</li> </ul> <p>Company Y an AI project featuring a private ChatGPT-like tool, streamlining mobility data analysis and advancing digital innovation in public sector policy evaluation.</p>"},{"location":"portfolio/projects/project-2/#challenge","title":"Challenge","text":"<p>The regional data team at Company Y faced the challenge of analyzing complex mobility data, including cars, bridges, traffic, and cyclists. Tasked with assessing policy compliance and the impact of changes, they struggled with data scattered across multiple systems, such as the Dexter portal's structured SQL data and various policy documents. This dispersion made analysis laborious, prompting the Province to explore how digitization and AI could streamline the process and foster innovation.</p>"},{"location":"portfolio/projects/project-2/#our-approach","title":"Our Approach","text":"<p>To tackle this challenge, we developed a custom-built AI solution similar to a \"private version of ChatGPT.\" This tool was designed to access and analyze large volumes of PDF documents and structured data exported from the Dexter database. By enabling a ChatGPT-like interaction, users could query this diverse data pool in a conversational manner, leveraging the AI to gain company-specific insights.</p>"},{"location":"portfolio/projects/project-2/#results-impact","title":"Results &amp; Impact","text":"<ul> <li>Successfully integrated structured SQL data and unstructured PDF documents</li> <li>Featured in major company meetings</li> <li>Enabled conversational querying of complex mobility data</li> <li>Streamlined policy compliance assessment</li> <li>Enhanced decision-making through comprehensive data analysis</li> </ul>"},{"location":"portfolio/projects/project-2/#solution-overview","title":"Solution Overview","text":"<p>Baseline OpenAI end-to-end chat reference architecture</p>"},{"location":"portfolio/projects/project-2/#tech-stack","title":"Tech Stack","text":"<ul> <li>OpenAI</li> <li>Pinecone vector database</li> <li>Microsoft Azure cloud infrastructure</li> <li>Python backend services</li> <li>FastAPI for RESTful endpoints</li> <li>Docker containerization</li> <li>GitHub Actions for CI/CD pipeline</li> </ul>"},{"location":"portfolio/projects/project-2/#additional-context","title":"Additional Context","text":"<ul> <li>Timeline: 3 months</li> <li>Team Size: 2 people</li> <li>Role: AI Engineer</li> <li>Expertise in custom chatbot development</li> <li>Specialization in retrieval-augmented generation</li> <li>Focus on OpenAI model integration</li> </ul> <ul> <li> <p> Let's have a virtual coffee together!</p> <p>Want to see if we're a match? Let's have a chat and find out. Schedule a free 30-minute strategy session to discuss your AI challenges and explore how we can work together.</p> <p>Book Free Intro Call </p> </li> </ul>"}]}